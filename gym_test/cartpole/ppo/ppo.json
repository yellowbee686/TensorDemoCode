{
  "type": "ppo_agent",
  "baseline_mode": "states",
  "baseline": {
      "type": "mlp",
      "sizes": [32, 32]
  },
  "baseline_optimizer": {
      "type": "multi_step",
      "optimizer": {
          "type": "adam",
          "learning_rate": 1e-4
      },
      "num_steps": 10
  },
  "discount": 0.99,
  "entropy_regularization": 1e-2,
  "optimization_steps":10,
  "gae_lambda": 0.97,
  "likelihood_ratio_clipping":0.2,
  "step_optimizer": {
      "type": "adam",
      "learning_rate": 1e-3
  },
  "batch_size":4096,
  "summary_spec": {
    "directory" : "./ppo",
    "labels": ["inputs", "losses", "variables", "activations", "gradients", "regularization"],
    "steps": 200
  },
  "keep_last_timestep": true
}